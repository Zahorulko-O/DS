{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Import libraries and set desired options\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "21669     0\n",
       "54843     0\n",
       "77292     0\n",
       "114021    0\n",
       "146670    0\n",
       "         ..\n",
       "12224     0\n",
       "164438    0\n",
       "12221     0\n",
       "156968    0\n",
       "204762    0\n",
       "Name: target, Length: 253561, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df = pd.read_csv(os.path.join(path, 'train_sessions.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(path, 'test_sessions.csv'), index_col='session_id')\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "y = train_df['target']\n",
    "train_df.fillna(0, inplace = True)\n",
    "test_df.fillna(0, inplace = True)\n",
    "test_df[times] = test_df[times].astype('datetime64')\n",
    "train_df[times] = train_df[times].astype('datetime64')\n",
    "y.astype('int8').values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12224</th>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164438</th>\n",
       "      <td>4207</td>\n",
       "      <td>753.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4207.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>52</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>7330.0</td>\n",
       "      <td>3594.0</td>\n",
       "      <td>3329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156968</th>\n",
       "      <td>3328</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>3328.0</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204762</th>\n",
       "      <td>222</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253561 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1   site2   site3   site4   site5   site6   site7   site8  \\\n",
       "session_id                                                                  \n",
       "21669          56    55.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "54843          56    55.0    56.0    55.0     0.0     0.0     0.0     0.0   \n",
       "77292         946   946.0   951.0   946.0   946.0   945.0   948.0   784.0   \n",
       "114021        945   948.0   949.0   948.0   945.0   946.0   947.0   945.0   \n",
       "146670        947   950.0   948.0   947.0   950.0   952.0   946.0   951.0   \n",
       "...           ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "12224          50    50.0    48.0    49.0    48.0    52.0    52.0    49.0   \n",
       "164438       4207   753.0   753.0    52.0    50.0  4207.0  3346.0  3359.0   \n",
       "12221          52  3346.0   784.0   784.0  3346.0   979.0  3324.0  7330.0   \n",
       "156968       3328  3324.0  3599.0  3413.0   753.0  3328.0  3599.0  3359.0   \n",
       "204762        222  3346.0  3346.0  3359.0    55.0  2891.0  3346.0     0.0   \n",
       "\n",
       "             site9  site10  \n",
       "session_id                  \n",
       "21669          0.0     0.0  \n",
       "54843          0.0     0.0  \n",
       "77292        949.0   946.0  \n",
       "114021       946.0   946.0  \n",
       "146670       946.0   947.0  \n",
       "...            ...     ...  \n",
       "12224        303.0   304.0  \n",
       "164438      3346.0    38.0  \n",
       "12221       3594.0  3329.0  \n",
       "156968      3359.0  3346.0  \n",
       "204762         0.0     0.0  \n",
       "\n",
       "[253561 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions =  test_df.loc[:,(sites)]\n",
    "train_sessions = train_df.loc[:,(sites)]\n",
    "test_times =  test_df.loc[:,(times)]\n",
    "train_times = train_df.loc[:,(times)]\n",
    "train_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def prepare_sparse_data(df_csv, dic_pkl):\n",
    "    df_csv.fillna(0, inplace = True)\n",
    "    df_csv[sites] = df_csv[sites]\n",
    "   # df_csv[times] = df_csv[times].astype('datetime64')\n",
    "    df_csv.fillna(0, inplace = True)\n",
    "    with open(dic_pkl, \"rb\") as input_dict:\n",
    "        site_dict=pickle.load(input_dict)\n",
    "    name_site = {val:key for (key, val) in site_dict.items()}\n",
    "    name_site[0] = 'unknown'\n",
    "    df_csv = df_csv[sites].apply(lambda row: ' '.join([name_site[i] for i in row]), axis=1).tolist()\n",
    "    \n",
    "    return df_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sessions  = prepare_sparse_data(test_sessions,  \n",
    "                      \"catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/site_dic.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = prepare_sparse_data(train_sessions,\n",
    "                         \"catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/site_dic.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 5), max_features=50000)#, tokenizer=(lambda s: s.split()))\n",
    "#vectorizer = TfidfVectorizer(ngram_range=(1, 5),\n",
    "#                               max_features=80000) #0.87\n",
    "#vectorizer = TfidfVectorizer(ngram_range=(1, 3),\n",
    "#                               max_features=80000, tokenizer=(lambda s: s.split())) 0.48\n",
    "#vectorizer = TfidfVectorizer(ngram_range=(1, 3),\n",
    "#                               max_features=50000, tokenizer=(lambda s: s.split())) 0.48\n",
    "#vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_sessions)\n",
    "X_test = vectorizer.transform(test_sessions)\n",
    "y_train = y.astype('int').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82797, 50000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82797, 50000)\n",
      "Wall time: 13.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82797, 11)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#19-02-2019\n",
    "def prepare_df_set_features(df_csv, df_times, X_sparse):\n",
    "        \n",
    "    times = ['time%s' % i for i in range(1, 11)]\n",
    "    sites = ['site%s' % i for i in range(1, 11)]   \n",
    "    print(X_sparse.shape)\n",
    "    #year\n",
    "    year = df_times['time1'].apply(lambda x: int(x.strftime(\"%Y\"))).astype('int').values.reshape(-1, 1)\n",
    "    day = df_times['time1'].apply(lambda x: int(x.strftime(\"%d\"))).astype('int').values.reshape(-1, 1)\n",
    "    month = df_times['time1'].apply(lambda x: int(x.strftime(\"%m\"))).astype('int').values.reshape(-1, 1)\n",
    " #   year1_4 = (month <= 3).astype('int').reshape(-1, 1)\n",
    " #   year2_4 = ((month > 3) & (month <= 6)).astype('int').reshape(-1, 1)\n",
    " #   year3_4 = ((month > 6) & (month <= 9)).astype('int').reshape(-1, 1)\n",
    " #   year4_4 = (month < 9).astype('int').reshape(-1, 1)\n",
    "#   print(\"day \", day.shape)\n",
    "    #start_hour\n",
    "    start_hour = df_times['time1'].apply(lambda x: int(x.strftime(\"%H\"))).astype('int').values.reshape(-1, 1)\n",
    "#    print(\"start_hour  \", start_hour.shape)\n",
    "   # train_df['start_hour'] = train_df['time1'].apply(lambda ts: ts.hour)\n",
    "    \n",
    "#    sess_duration = (df_times.max(axis=1) - df_times.min(axis=1)).astype('timedelta64[s]')\\\n",
    "#            .astype('int').values.reshape(-1, 1)\n",
    "    #day_of_week\n",
    "    day_of_week = df_times['time1'].apply(lambda x: int(x.strftime(\"%u\"))).astype('int').values.reshape(-1, 1)\n",
    " #  print(\"day_of_week  \", day_of_week.shape)\n",
    "    weekday = (day_of_week >= 6).astype('int').reshape(-1, 1)\n",
    "#   print(\"weekday  \", weekday.shape)\n",
    "    workday = (day_of_week < 6).astype('int').reshape(-1, 1)\n",
    "#   print(\"workday  \", workday.shape)\n",
    "\n",
    "  #  day_of_year = df_times['time1'].apply(lambda x: int(x.strftime(\"%j\"))).astype('int').values.reshape(-1, 1)\n",
    "#   print(\"day_of_year  \", day_of_year.shape)\n",
    "        #day of months                               \n",
    "    day_of_months = df_times['time1'].apply(lambda x: int(x.strftime(\"%d\"))).values.reshape(-1, 1)\n",
    "\n",
    "    day_of_months_1_2 = (day_of_months <= 15).astype('int').reshape(-1, 1)\n",
    "\n",
    "    day_of_months_2_2 = (day_of_months <= 16).astype('int').reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "   # df_csv.fillna(0, inplace = True)\n",
    "     \n",
    "    hour = df_times['time1'].apply(lambda ts: ts.hour).astype('int').values.reshape(-1, 1)\n",
    "#    print(\"hour  \", hour.shape) \n",
    "    morning_h = ((hour >= 7) & (hour <= 11)).astype('int').reshape(-1, 1)\n",
    "#    print(\"morning_h  \", morning_h.shape) \n",
    "    day_h = ((hour >= 12) & (hour <= 18)).astype('int').reshape(-1, 1)\n",
    "#    print(\"day_h  \", day_h.shape) \n",
    "    evening_h = ((hour >= 19) & (hour <= 23)).astype('int').reshape(-1, 1)\n",
    "#    print(\"evening_h  \", evening_h .shape)\n",
    "    night_h = ((hour >= 0) & (hour <= 6)).astype('int').reshape(-1, 1)\n",
    "#    print(\"night_h  \", night_h.shape) \n",
    "    \n",
    "    \n",
    "\n",
    "    X = np.hstack([ year, month, day,  start_hour,  weekday, day_of_months, workday, hour, morning_h, day_h, evening_h])\n",
    "  #  X = np.concatenate((year, day, start_hour,  day_of_week, weekday, workday,\n",
    "   #       day_of_months, day_of_months_1_2, day_of_months_2_2, hour, morning_h, day_h, evening_h, night_h, X_sparse), axis=1)\n",
    "    #    print(\"X\", X)\n",
    "    return X\n",
    "\n",
    "X_fit_test = prepare_df_set_features(test_df, test_times, X_test)\n",
    "X_fit_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = csr_matrix(hstack([X_test, X_fit_test]))\n",
    "#X = np.hstack([csr_matrix(X_test), X_fit_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 50000)\n",
      "Wall time: 42.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(253561, 50011)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_fit_train = prepare_df_set_features(train_df, train_times,  X_train)\n",
    "X_train_all= csr_matrix(hstack([X_train, X_fit_train]))\n",
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear (logit_grid_searcher )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.9064983236097829\n",
      "Wall time: 9min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#with timer('Cross-validation'):\n",
    "time_split = TimeSeriesSplit()\n",
    "logit = LogisticRegression(random_state=7, solver='liblinear',  class_weight= 'balanced')\n",
    "c_values=np.arange(5,6, 0.1)\n",
    "#range(1, 10, 10)\n",
    "#c_values = np.logspace(0, 1, 10)\n",
    "\n",
    "#'penalty':['l1','l2']\n",
    "logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': [5.5]},\n",
    "                                  scoring='roc_auc',  cv=time_split, verbose=1)\n",
    "logit_grid_searcher.fit(X_train_all, y)\n",
    "print('CV score', logit_grid_searcher.best_score_)\n",
    "\n",
    "\n",
    "test_pred = logit_grid_searcher.predict_proba(X_test_all)[:, 1]\n",
    "pred_df = pd.DataFrame(test_pred, index=np.arange(1, test_pred.shape[0] + 1),\n",
    "                       columns=['target'])\n",
    "pred_df.to_csv(f'submission_lg_{1}.csv', index_label='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.5, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=7, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X = np.hstack([ year, month, day,  start_hour,  weekday, \n",
    "       workday, hour, morning_h, day_h, evening_h])\n",
    "CV score 0.9108495258250623\n",
    "Wall time: 3min    \n",
    "LogisticRegression(C=5.5, class_weight='balanced', dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=7, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([ year, month, day,  start_hour,  weekday, day_of_months, day_of_months_1_2,\n",
    "       day_of_months_2_2,  workday, hour, morning_h, day_h, evening_h])\n",
    "\n",
    "CV score 0.9091891916048932\n",
    "Wall time: 4min 2s\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 5), max_features=80000, tokenizer=(lambda s: s.split()))\n",
    "\n",
    "LogisticRegression(C=5.5, class_weight='balanced', dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=7, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear (logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Penalty term must be positive; got (C=[5.5])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m             raise ValueError(\"Penalty term must be positive; got (C=%r)\"\n\u001b[1;32m-> 1497\u001b[1;33m                              % self.C)\n\u001b[0m\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'elasticnet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m             if (not isinstance(self.l1_ratio, numbers.Number) or\n",
      "\u001b[1;31mValueError\u001b[0m: Penalty term must be positive; got (C=[5.5])"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#with timer('Cross-validation'):\n",
    "#time_split = TimeSeriesSplit()\n",
    "logit = LogisticRegression(random_state=7, 46C=[5.5], solver='liblinear',penalty='l1', class_weight= 'balanced')\n",
    "#c_values=range(1, 10, 1)\n",
    "c_values = 3,59\n",
    "#np.logspace(0, 1, 10)\n",
    "\n",
    "#'penalty':['l1','l2']\n",
    "#logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "#                                  scoring='roc_auc',  cv=time_split, verbose=1)\n",
    "logit.fit(X_train_all, y)\n",
    "print('CV score', logit.score(X_train_all, y))\n",
    "\n",
    "\n",
    "test_pred = logit.predict_proba(X_test_all)[:, 1]\n",
    "pred_df = pd.DataFrame(test_pred, index=np.arange(1, test_pred.shape[0] + 1),\n",
    "                       columns=['target'])\n",
    "pred_df.to_csv(f'submission_l_{1}.csv', index_label='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определение влияния признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=7, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "clf.fit(X_fit_train, y)\n",
    "#print(np.hstack([np.array(independent_columns_names).reshape(7,1),clf.coef_.reshape(7,1)]))\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([ year, day, month, year1_4, year2_4, year3_4, year4_4 , start_hour, sess_duration, \n",
    "                   day_of_week, weekday, workday, day_of_year, day_of_months, day_of_months_1_2, \n",
    "                   day_of_months_2_2, hour, morning_h, day_h , evening_h, night_h])\n",
    "\n",
    "clf.coef_:\n",
    "array([[-1.67226036e-03, -1.54068005e-05, -3.62233605e-06,\n",
    "        -5.26207369e-07, -1.30127047e-07, -4.77259197e-09,\n",
    "        -6.57561572e-07, -9.96692728e-06, -2.14024312e-09,\n",
    "        -2.76419036e-06, -7.84659390e-08, -7.51966891e-07,\n",
    "        -9.98491908e-05, -1.54068005e-05, -2.62131883e-07,\n",
    "        -2.80592649e-07, -9.96692728e-06, -4.31354515e-07,\n",
    "        -3.77801833e-07, -2.12764825e-08,  0.00000000e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[-4.35647586e-03,  5.15765659e-03, -9.30459002e-03,\n",
    "        -3.94171496e-01, -4.93501872e-02,  2.19233947e+00,\n",
    "        -7.60439582e-01,  3.12826781e-01, -3.87077760e-01,\n",
    "        -2.89894727e-01, -1.89741961e-03,  5.15765659e-03,\n",
    "        -6.12239996e-01,  1.93821477e+00, -1.32580590e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
